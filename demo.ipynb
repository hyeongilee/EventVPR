{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import slayerSNN as snn\n",
    "from learningStats import learningStats\n",
    "from IPython.display import HTML\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netParams = snn.params('network.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "class nmnistDataset(Dataset):\n",
    "    def __init__(self, datasetPath, sampleFile, samplingTime, sampleLength):\n",
    "        self.path = datasetPath \n",
    "        self.samples = np.loadtxt(sampleFile).astype('int')\n",
    "        self.samplingTime = samplingTime\n",
    "        self.nTimeBins    = int(sampleLength / samplingTime)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputIndex  = self.samples[index, 0]\n",
    "        classLabel  = self.samples[index, 1]\n",
    "\n",
    "        inputSpikes = snn.io.readNpSpikes(\n",
    "                        self.path + str(inputIndex.item()) + '.npy'\n",
    "                        ).toSpikeTensor(torch.zeros((2,160,120,self.nTimeBins)),\n",
    "                        samplingTime=self.samplingTime)\n",
    "        desiredClass = torch.zeros((2, 1, 1, 1))\n",
    "        desiredClass[classLabel,...] = 1\n",
    "        return inputSpikes, desiredClass, classLabel\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, netParams):\n",
    "        super(Network, self).__init__()\n",
    "        # initialize slayer\n",
    "        slayer = snn.layer(netParams['neuron'], netParams['simulation'])\n",
    "        self.slayer = slayer\n",
    "        # define network functions\n",
    "        self.conv1 = slayer.conv(2, 8, 4, stride=2, padding=1)\n",
    "        self.conv2 = slayer.conv(8, 16, 4, stride=2, padding=1)\n",
    "        self.conv3 = slayer.conv(16, 32, 4, padding=1)\n",
    "        self.pool1 = slayer.pool(2)\n",
    "        self.pool2 = slayer.pool(2)\n",
    "        self.fc1   = slayer.dense((7, 9, 32), 2)\n",
    "\n",
    "    def forward(self, spikeInput):\n",
    "        spikeLayer1 = self.slayer.spike(self.conv1(self.slayer.psp(spikeInput ))) # 32, 32, 16\n",
    "        spikeLayer2 = self.slayer.spike(self.pool1(self.slayer.psp(spikeLayer1))) # 16, 16, 16\n",
    "        spikeLayer3 = self.slayer.spike(self.conv2(self.slayer.psp(spikeLayer2))) # 16, 16, 32\n",
    "        spikeLayer4 = self.slayer.spike(self.pool2(self.slayer.psp(spikeLayer3))) #  8,  8, 32\n",
    "        spikeLayer5 = self.slayer.spike(self.conv3(self.slayer.psp(spikeLayer4))) #  8,  8, 64\n",
    "        spikeOut    = self.slayer.spike(self.fc1  (self.slayer.psp(spikeLayer5))) #  10\n",
    "\n",
    "        return spikeOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cuda device to run the code on.\n",
    "# device = torch.device('cuda')\n",
    "# Use multiple GPU's if available\n",
    "device = torch.device('cuda:0') # should be the first GPU of deviceIDs\n",
    "deviceIds = [0, 1]\n",
    "\n",
    "# Create network instance.\n",
    "# net = Network(netParams).to(device)\n",
    "# Split the network to run over multiple GPUs\n",
    "net = torch.nn.DataParallel(Network(netParams).to(device), device_ids=deviceIds)\n",
    "\n",
    "# Create snn loss instance.\n",
    "error = snn.loss(netParams).to(device)\n",
    "\n",
    "# Define optimizer module.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01, amsgrad = True)\n",
    "    \n",
    "# Dataset and dataLoader instances.\n",
    "trainingSet = nmnistDataset(datasetPath =netParams['training']['path']['in'], \n",
    "                            sampleFile  =netParams['training']['path']['train'],\n",
    "                            samplingTime=netParams['simulation']['Ts'],\n",
    "                            sampleLength=netParams['simulation']['tSample'])\n",
    "trainLoader = DataLoader(dataset=trainingSet, batch_size=3, shuffle=True, num_workers=2)\n",
    "\n",
    "testingSet = nmnistDataset(datasetPath  =netParams['training']['path']['in'], \n",
    "                            sampleFile  =netParams['training']['path']['test'],\n",
    "                            samplingTime=netParams['simulation']['Ts'],\n",
    "                            sampleLength=netParams['simulation']['tSample'])\n",
    "testLoader = DataLoader(dataset=testingSet, batch_size=3, shuffle=True, num_workers=2)\n",
    "\n",
    "# Learning stats instance.\n",
    "stats = learningStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input, target, label = trainingSet[22]\n",
    "print(target)\n",
    "print(label)\n",
    "print(input.shape)\n",
    "anim = snn.io.animTD(snn.io.spikeArrayToEvent(input.reshape((2, 160, 120, -1)).cpu().data.numpy()))\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    # Reset training stats.\n",
    "    stats.training.reset()\n",
    "    tSt = datetime.now()\n",
    "\n",
    "    # Training loop.\n",
    "    for i, (input, target, label) in enumerate(trainLoader, 0):\n",
    "        # Move the input and target to correct GPU.\n",
    "        input  = input.to(device)\n",
    "        target = target.to(device) \n",
    "\n",
    "        # Forward pass of the network.\n",
    "        output = net.forward(input)\n",
    "\n",
    "        # Gather the training stats.\n",
    "        stats.training.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n",
    "        stats.training.numSamples     += len(label)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = error.numSpikes(output, target)\n",
    "\n",
    "        # Reset gradients to zero.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass of the network.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather training loss stats.\n",
    "        stats.training.lossSum += loss.cpu().data.item()\n",
    "\n",
    "        # Display training stats. (Suitable for normal python implementation)\n",
    "        # stats.print(epoch, i, (datetime.now() - tSt).total_seconds())\n",
    "\n",
    "    # Update training stats.\n",
    "    stats.training.update()\n",
    "    # Reset testing stats.\n",
    "    stats.testing.reset()\n",
    "\n",
    "    # Testing loop.\n",
    "    # Same steps as Training loops except loss backpropagation and weight update.\n",
    "    for i, (input, target, label) in enumerate(testLoader, 0):\n",
    "        input  = input.to(device)\n",
    "        target = target.to(device) \n",
    "\n",
    "        output = net.forward(input)\n",
    "\n",
    "        stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n",
    "        stats.testing.numSamples     += len(label)\n",
    "\n",
    "        loss = error.numSpikes(output, target)\n",
    "        stats.testing.lossSum += loss.cpu().data.item()\n",
    "        # stats.print(epoch, i)\n",
    "\n",
    "    # Update testing stats.\n",
    "    stats.testing.update()\n",
    "    if epoch%1==0:  stats.print(epoch, timeElapsed=(datetime.now() - tSt).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.semilogy(stats.training.lossLog, label='Training')\n",
    "plt.semilogy(stats.testing .lossLog, label='Testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(stats.training.accuracyLog, label='Training')\n",
    "plt.plot(stats.testing .accuracyLog, label='Testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
