{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(database_seq, query_seq):\n",
    "    N_d = database_seq.shape[0]\n",
    "    N_q = query_seq.shape[0]\n",
    "    data = database_seq.tolist()\n",
    "    temp = query_seq.tolist()\n",
    "    for i in range(N_q):\n",
    "        temp[i][2] = 0\n",
    "    data.extend(temp)\n",
    "    data = sorted(data, key = lambda x : x[3])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0d928e3973bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mq_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mq_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2020_07_30_18_17_05/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclean_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_array_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Header is not a dictionary: {!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'descr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fortran_order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Header does not contain the correct keys: {!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ms = 100\n",
    "database_file = \"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "query_file = \"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "database_utm_file_1 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_08_58_location.txt\",'r')\n",
    "query_utm_file_1 = open(\"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/2020_07_30_17_51_53_location.txt\",'r')\n",
    "database_utm_file_2 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_16_38_location.txt\",'r')\n",
    "query_utm_file_2 = open(\"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/2020_07_30_18_17_05_location.txt\",'r')\n",
    "database_utm_file_3 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_24_02_location.txt\",'r')\n",
    "output_location = \"/media/student1/770a08ae-0a7d-4b62-bbf4-b81fdd9baf2a/train_dataset_\"+str(ms)+\"ms/\"\n",
    "\n",
    "ground_file = open(output_location+\"train.txt\",'w')\n",
    "\n",
    "DD = list()\n",
    "QQ = list()\n",
    "\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "\n",
    "threshold = 10 #m\n",
    "T = 150000\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_2.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_3.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_3.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_2.close()\n",
    "\n",
    "S = set()\n",
    "\n",
    "n_true_set = 0\n",
    "n_false_set = 0\n",
    "\n",
    "while n_true_set < 50000:\n",
    "    clean_set = random.randint(1,3)\n",
    "    rain_set = random.randint(1,2)\n",
    "    d_str = \"\"\n",
    "    if clean_set == 1:\n",
    "        d_num = random.randint(0,len(DD[0])-1)\n",
    "        d_str = \"2020_07_04_11_08_58/\"\n",
    "    elif clean_set == 2:\n",
    "        d_num = random.randint(0,len(DD[1])-1)\n",
    "        d_str = \"2020_07_04_11_16_38/\"\n",
    "    elif clean_set == 3:\n",
    "        d_num = random.randint(0,len(DD[2])-1)\n",
    "        d_str = \"2020_07_04_11_24_02/\"\n",
    "    clean_file = np.load(database_file + d_str + str(d_num) + \".npy\")\n",
    "    \n",
    "    q_str = \"\"\n",
    "    if rain_set == 1:\n",
    "        q_num = random.randint(0,len(QQ[0])-1)\n",
    "        q_str = \"2020_07_30_17_51_53/\"\n",
    "    elif rain_set == 2:\n",
    "        q_num = random.randint(0,len(QQ[1])-1)\n",
    "        q_str = \"2020_07_30_18_17_05/\"\n",
    "    rain_file = np.load(query_file + q_str + str(q_num) + \".npy\")\n",
    "    if (clean_set,d_num,rain_set,q_num) in S:\n",
    "        continue\n",
    "    if rain_file.shape[0] > T:\n",
    "        continue\n",
    "    utm_d = (DD[clean_set-1][d_num][1],DD[clean_set-1][d_num][2])\n",
    "    utm_q = (QQ[rain_set-1][q_num][1],QQ[rain_set-1][q_num][2])\n",
    "    d = distance.euclidean(utm_d, utm_q)\n",
    "    #print(\"Euclidean distance: \", d)\n",
    "    if d <= threshold:\n",
    "        ground_file.write(str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t1\\n\")\n",
    "        n_true_set += 1\n",
    "    else:\n",
    "        if n_false_set >= n_true_set:\n",
    "            continue\n",
    "        ground_file.write(str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t0\\n\")\n",
    "        n_false_set += 1\n",
    "    #print(str(clean_set)+'0'+str(d_num)+'0'+str(rain_set)+'0'+str(q_num), n_true_set,n_false_set)\n",
    "    S.add((clean_set,d_num,rain_set,q_num))\n",
    "    result = merge(clean_file, rain_file)\n",
    "    np.save(output_location+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\".npy\",result)\n",
    "    \n",
    "        \n",
    "\n",
    "database_utm_file_1.close()\n",
    "database_utm_file_2.close()\n",
    "database_utm_file_3.close()\n",
    "query_utm_file_1.close()\n",
    "query_utm_file_2.close()\n",
    "ground_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file = \"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "query_file = \"../dataset/KH/night/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "database_utm_file_1 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_08_58_location.txt\",'r')\n",
    "query_utm_file_1 = open(\"../dataset/KH/night/raw_numpy_\"+str(ms)+\"ms/2020_07_31_20_23_29_location.txt\",'r')\n",
    "database_utm_file_2 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_16_38_location.txt\",'r')\n",
    "database_utm_file_3 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_24_02_location.txt\",'r')\n",
    "output_location = \"/media/student1/770a08ae-0a7d-4b62-bbf4-b81fdd9baf2a/train_dataset_\"+str(ms)+\"ms/\"\n",
    "\n",
    "ground_file = open(output_location+\"train_temp.txt\",'w')\n",
    "\n",
    "DD = list()\n",
    "QQ = list()\n",
    "\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "\n",
    "threshold = 10 #m\n",
    "T = 150000\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_2.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_3.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_3.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_1.close()\n",
    "\n",
    "S = set()\n",
    "\n",
    "n_true_set = 0\n",
    "n_false_set = 0\n",
    "\n",
    "while n_true_set < 25000:\n",
    "    clean_set = random.randint(1,3)\n",
    "    night_set = 3\n",
    "    d_str = \"\"\n",
    "    if clean_set == 1:\n",
    "        d_num = random.randint(0,len(DD[0])-1)\n",
    "        d_str = \"2020_07_04_11_08_58/\"\n",
    "    elif clean_set == 2:\n",
    "        d_num = random.randint(0,len(DD[1])-1)\n",
    "        d_str = \"2020_07_04_11_16_38/\"\n",
    "    elif clean_set == 3:\n",
    "        d_num = random.randint(0,len(DD[2])-1)\n",
    "        d_str = \"2020_07_04_11_24_02/\"\n",
    "    clean_file = np.load(database_file + d_str + str(d_num) + \".npy\")\n",
    "    \n",
    "    q_str = \"\"\n",
    "    if night_set == 3:\n",
    "        q_num = random.randint(0,len(QQ[0])-1)\n",
    "        q_str = \"2020_07_31_20_23_29/\"\n",
    "    night_file = np.load(query_file + q_str + str(q_num) + \".npy\")\n",
    "    if (clean_set,d_num,night_set,q_num) in S:\n",
    "        continue\n",
    "    if night_file.shape[0] > T:\n",
    "        continue\n",
    "    utm_d = (DD[clean_set-1][d_num][1],DD[clean_set-1][d_num][2])\n",
    "    utm_q = (QQ[night_set-3][q_num][1],QQ[night_set-3][q_num][2])\n",
    "    d = distance.euclidean(utm_d, utm_q)\n",
    "    #print(\"Euclidean distance: \", d)\n",
    "    if d <= threshold:\n",
    "        ground_file.write(str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t1\\n\")\n",
    "        n_true_set += 1\n",
    "    else:\n",
    "        if n_false_set >= n_true_set:\n",
    "            continue\n",
    "        ground_file.write(str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t0\\n\")\n",
    "        n_false_set += 1\n",
    "    #print(str(clean_set)+'0'+str(d_num)+'0'+str(night_set)+'0'+str(q_num), n_true_set,n_false_set)\n",
    "    S.add((clean_set,d_num,night_set,q_num))\n",
    "    result = merge(clean_file, night_file)\n",
    "    np.save(output_location+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\".npy\",result)\n",
    "    \n",
    "        \n",
    "\n",
    "database_utm_file_1.close()\n",
    "database_utm_file_2.close()\n",
    "database_utm_file_3.close()\n",
    "query_utm_file_1.close()\n",
    "ground_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file = \"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "query_file = \"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "database_utm_file_1 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_08_58_location.txt\",'r')\n",
    "query_utm_file_1 = open(\"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/2020_07_30_17_51_53_location.txt\",'r')\n",
    "database_utm_file_2 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_16_38_location.txt\",'r')\n",
    "query_utm_file_2 = open(\"../dataset/KH/rain/raw_numpy_\"+str(ms)+\"ms/2020_07_30_18_17_05_location.txt\",'r')\n",
    "database_utm_file_3 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_24_02_location.txt\",'r')\n",
    "output_location = \"/media/student1/770a08ae-0a7d-4b62-bbf4-b81fdd9baf2a/train_dataset_\"+str(ms)+\"ms/\"\n",
    "\n",
    "ground_file = open(output_location+\"test.txt\",'w')\n",
    "\n",
    "DD = list()\n",
    "QQ = list()\n",
    "\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "\n",
    "threshold = 10 #m\n",
    "T = 150000\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_2.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_3.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_3.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_2.close()\n",
    "\n",
    "S = set()\n",
    "\n",
    "n_true_set = 0\n",
    "n_false_set = 0\n",
    "\n",
    "while n_true_set < 1000:\n",
    "    clean_set = random.randint(1,3)\n",
    "    rain_set = random.randint(1,2)\n",
    "    d_str = \"\"\n",
    "    if clean_set == 1:\n",
    "        d_num = random.randint(0,len(DD[0])-1)\n",
    "        d_str = \"2020_07_04_11_08_58/\"\n",
    "    elif clean_set == 2:\n",
    "        d_num = random.randint(0,len(DD[1])-1)\n",
    "        d_str = \"2020_07_04_11_16_38/\"\n",
    "    elif clean_set == 3:\n",
    "        d_num = random.randint(0,len(DD[2])-1)\n",
    "        d_str = \"2020_07_04_11_24_02/\"\n",
    "    clean_file = np.load(database_file + d_str + str(d_num) + \".npy\")\n",
    "    \n",
    "    q_str = \"\"\n",
    "    if rain_set == 1:\n",
    "        q_num = random.randint(0,len(QQ[0])-1)\n",
    "        q_str = \"2020_07_30_17_51_53/\"\n",
    "    elif rain_set == 2:\n",
    "        q_num = random.randint(0,len(QQ[1])-1)\n",
    "        q_str = \"2020_07_30_18_17_05/\"\n",
    "    rain_file = np.load(query_file + q_str + str(q_num) + \".npy\")\n",
    "    if (clean_set,d_num,rain_set,q_num) in S:\n",
    "        continue\n",
    "    if rain_file.shape[0] > T:\n",
    "        continue\n",
    "    utm_d = (DD[clean_set-1][d_num][1],DD[clean_set-1][d_num][2])\n",
    "    utm_q = (QQ[rain_set-1][q_num][1],QQ[rain_set-1][q_num][2])\n",
    "    d = distance.euclidean(utm_d, utm_q)\n",
    "    #print(\"Euclidean distance: \", d)\n",
    "    if d <= threshold:\n",
    "        ground_file.write('60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t1\\n\")\n",
    "        n_true_set += 1\n",
    "    else:\n",
    "        if n_false_set >= n_true_set:\n",
    "            continue\n",
    "        ground_file.write('60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t0\\n\")\n",
    "        n_false_set += 1\n",
    "    #print('60'+str(clean_set)+'0'+str(d_num)+'0'+str(rain_set)+'0'+str(q_num), n_true_set,n_false_set)\n",
    "    S.add((clean_set,d_num,rain_set,q_num))\n",
    "    result = merge(clean_file, rain_file)\n",
    "    np.save(output_location+'60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\".npy\",result)\n",
    "    \n",
    "        \n",
    "\n",
    "database_utm_file_1.close()\n",
    "database_utm_file_2.close()\n",
    "database_utm_file_3.close()\n",
    "query_utm_file_1.close()\n",
    "query_utm_file_2.close()\n",
    "ground_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file = \"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "query_file = \"../dataset/KH/night/raw_numpy_\"+str(ms)+\"ms/\"\n",
    "database_utm_file_1 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_08_58_location.txt\",'r')\n",
    "query_utm_file_1 = open(\"../dataset/KH/night/raw_numpy_\"+str(ms)+\"ms/2020_07_31_20_23_29_location.txt\",'r')\n",
    "database_utm_file_2 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_16_38_location.txt\",'r')\n",
    "database_utm_file_3 = open(\"../dataset/KH/clean/raw_numpy_\"+str(ms)+\"ms/2020_07_04_11_24_02_location.txt\",'r')\n",
    "output_location = \"/media/student1/770a08ae-0a7d-4b62-bbf4-b81fdd9baf2a/train_dataset_\"+str(ms)+\"ms/\"\n",
    "\n",
    "ground_file = open(output_location+\"test_temp.txt\",'w')\n",
    "\n",
    "DD = list()\n",
    "QQ = list()\n",
    "\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "\n",
    "threshold = 10 #m\n",
    "T = 150000\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_1.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_2.close()\n",
    "\n",
    "while True:\n",
    "    line = database_utm_file_3.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    D_utm.append(item)\n",
    "DD.append(D_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "database_utm_file_3.close()\n",
    "\n",
    "while True:\n",
    "    line = query_utm_file_1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_list = line.split()\n",
    "    item = [int(line_list[0]),float(line_list[1]),float(line_list[2])]\n",
    "    Q_utm.append(item)\n",
    "QQ.append(Q_utm)\n",
    "D_utm = list()\n",
    "Q_utm = list()\n",
    "query_utm_file_1.close()\n",
    "\n",
    "S = set()\n",
    "\n",
    "n_true_set = 0\n",
    "n_false_set = 0\n",
    "\n",
    "while n_true_set < 500:\n",
    "    clean_set = random.randint(1,3)\n",
    "    night_set = 3\n",
    "    d_str = \"\"\n",
    "    if clean_set == 1:\n",
    "        d_num = random.randint(0,len(DD[0])-1)\n",
    "        d_str = \"2020_07_04_11_08_58/\"\n",
    "    elif clean_set == 2:\n",
    "        d_num = random.randint(0,len(DD[1])-1)\n",
    "        d_str = \"2020_07_04_11_16_38/\"\n",
    "    elif clean_set == 3:\n",
    "        d_num = random.randint(0,len(DD[2])-1)\n",
    "        d_str = \"2020_07_04_11_24_02/\"\n",
    "    clean_file = np.load(database_file + d_str + str(d_num) + \".npy\")\n",
    "    \n",
    "    q_str = \"\"\n",
    "    if night_set == 3:\n",
    "        q_num = random.randint(0,len(QQ[0])-1)\n",
    "        q_str = \"2020_07_31_20_23_29/\"\n",
    "    night_file = np.load(query_file + q_str + str(q_num) + \".npy\")\n",
    "    if (clean_set,d_num,night_set,q_num) in S:\n",
    "        continue\n",
    "    if night_file.shape[0] > T:\n",
    "        continue\n",
    "    utm_d = (DD[clean_set-1][d_num][1],DD[clean_set-1][d_num][2])\n",
    "    utm_q = (QQ[night_set-3][q_num][1],QQ[night_set-3][q_num][2])\n",
    "    d = distance.euclidean(utm_d, utm_q)\n",
    "    #print(\"Euclidean distance: \", d)\n",
    "    if d <= threshold:\n",
    "        ground_file.write('60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t1\\n\")\n",
    "        n_true_set += 1\n",
    "    else:\n",
    "        if n_false_set >= n_true_set:\n",
    "            continue\n",
    "        ground_file.write('60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\"\\t0\\n\")\n",
    "        n_false_set += 1\n",
    "    #print('60'+str(clean_set)+'0'+str(d_num)+'0'+str(night_set)+'0'+str(q_num), n_true_set,n_false_set)\n",
    "    S.add((clean_set,d_num,night_set,q_num))\n",
    "    result = merge(clean_file, night_file)\n",
    "    np.save(output_location+'60'+str(clean_set)+'0'*(4-len(str(d_num)))+str(d_num)+'0'+str(rain_set)+'0'*(4-len(str(q_num)))+str(q_num)+\".npy\",result)\n",
    "    \n",
    "        \n",
    "\n",
    "database_utm_file_1.close()\n",
    "database_utm_file_2.close()\n",
    "database_utm_file_3.close()\n",
    "query_utm_file_1.close()\n",
    "ground_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
